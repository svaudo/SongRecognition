{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d351cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from microphone import record_audio\n",
    "from typing import Tuple\n",
    "import librosa\n",
    "from random import randint\n",
    "from collections import Counter\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# For peak finding:\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
    "from scipy.ndimage.morphology import iterate_structure\n",
    "from typing import Tuple, Callable, List\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1382ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create functions for converting all variety of audio recordings into a NumPy-array of digital samples.\n",
    "\n",
    "def from_mp3(local_song_path: str, sr: int):\n",
    "    #Gets MP3 from disk\n",
    "    samples, sample_rate = librosa.load(local_song_path, sr=sr, mono=True)\n",
    "    #Turns MP3 into .npy\n",
    "    array = np.hstack([np.frombuffer(i, np.int16) for i in samples])\n",
    "    S = mlab.specgram(array,NFFT=4096,Fs=sample_rate,window=mlab.window_hanning,noverlap=4096 // 2,)[0]\n",
    "    print(local_song_path+\" loaded!\")\n",
    "    return S\n",
    "\n",
    "def from_recording(length: float, sr: int):\n",
    "    samples, sample_rate = record_audio(length)\n",
    "    \n",
    "    #Turns MP3 into .npy file and saves to disk\n",
    "    samples = np.hstack([np.frombuffer(i, np.int16) for i in samples])\n",
    "    array = np.hstack((sample_rate, samples)) #sample rate is first\n",
    "    \n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52396281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "# `@njit` \"decorates\" the `_peaks` function. This tells Numba to\n",
    "# compile this function using the \"low level virtual machine\" (LLVM)\n",
    "# compiler. The resulting object is a Python function that, when called,\n",
    "# executes optimized machine code instead of the Python code\n",
    "# \n",
    "# The code used in _peaks adheres strictly to the subset of Python and\n",
    "# NumPy that is supported by Numba's jit. This is a requirement in order\n",
    "# for Numba to know how to compile this function to more efficient\n",
    "# instructions for the machine to execute\n",
    "\n",
    "@njit\n",
    "\n",
    "def _peaks(\n",
    "    data_2d: np.ndarray, rows: np.ndarray, cols: np.ndarray, amp_min: float\n",
    ") -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    A Numba-optimized 2-D peak-finding algorithm.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected.\n",
    "\n",
    "    rows : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered row indices of the local neighborhood mask\n",
    "    \n",
    "    cols : numpy.ndarray, shape-(N,)\n",
    "        The 0-centered column indices of the local neighborhood mask\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location. \n",
    "    \"\"\"\n",
    "    \n",
    "    peaks = []  # stores the (row, col) locations of all the local peaks\n",
    "\n",
    "    # Iterate over the 2-D data in col-major order\n",
    "    # we want to see if there is a local peak located at\n",
    "    # row=r, col=c\n",
    "    for c, r in np.ndindex(*data_2d.shape[::-1]):\n",
    "        if data_2d[r, c] <= amp_min:\n",
    "            # The amplitude falls beneath the minimum threshold\n",
    "            # thus this can't be a peak.\n",
    "            continue\n",
    "        \n",
    "        # Iterating over the neighborhood centered on (r, c)\n",
    "        # dr: displacement from r\n",
    "        # dc: discplacement from c\n",
    "        for dr, dc in zip(rows, cols):\n",
    "            if dr == 0 and dc == 0:\n",
    "                # This would compare (r, c) with itself.. skip!\n",
    "                continue\n",
    "\n",
    "            if not (0 <= r + dr < data_2d.shape[0]):\n",
    "                # neighbor falls outside of boundary\n",
    "                continue\n",
    "\n",
    "            # mirror over array boundary\n",
    "            if not (0 <= c + dc < data_2d.shape[1]):\n",
    "                # neighbor falls outside of boundary\n",
    "                continue\n",
    "\n",
    "            if data_2d[r, c] < data_2d[r + dr, c + dc]:\n",
    "                # One of the amplitudes within the neighborhood\n",
    "                # is larger, thus data_2d[r, c] cannot be a peak\n",
    "                break\n",
    "        else:\n",
    "            # if we did not break from the for-loop then (r, c) is a peak\n",
    "            peaks.append((r, c))\n",
    "    return peaks\n",
    "\n",
    "# `local_peak_locations` is responsible for taking in the boolean mask `neighborhood`\n",
    "# and converting it to a form that can be used by `_peaks`. This \"outer\" code is \n",
    "# not compatible with Numba which is why we end up using two functions:\n",
    "# `local_peak_locations` does some initial pre-processing that is not compatible with\n",
    "# Numba, and then it calls `_peaks` which contains all of the jit-compatible code\n",
    "def local_peak_locations(data_2d: np.ndarray, neighborhood: np.ndarray, amp_min: float):\n",
    "    \"\"\"\n",
    "    Defines a local neighborhood and finds the local peaks\n",
    "    in the spectrogram, which must be larger than the specified `amp_min`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray, shape-(H, W)\n",
    "        The 2D array of data in which local peaks will be detected\n",
    "    \n",
    "    neighborhood : numpy.ndarray, shape-(h, w)\n",
    "        A boolean mask indicating the \"neighborhood\" in which each\n",
    "        datum will be assessed to determine whether or not it is\n",
    "        a local peak. h and w must be odd-valued numbers\n",
    "        \n",
    "    amp_min : float\n",
    "        All amplitudes at and below this value are excluded from being local \n",
    "        peaks.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Tuple[int, int]]\n",
    "        (row, col) index pair for each local peak location.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Neighborhoods that overlap with the boundary are mirrored across the boundary.\n",
    "    \n",
    "    The local peaks are returned in column-major order.\n",
    "    \"\"\"\n",
    "    \n",
    "    rows, cols = np.where(neighborhood)\n",
    "    assert neighborhood.shape[0] % 2 == 1\n",
    "    assert neighborhood.shape[1] % 2 == 1\n",
    "\n",
    "    # center neighborhood indices around center of neighborhood\n",
    "    rows -= neighborhood.shape[0] // 2\n",
    "    cols -= neighborhood.shape[1] // 2\n",
    "\n",
    "    return _peaks(data_2d, rows, cols, amp_min=amp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d87e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_peaks_mask(data: np.ndarray, cutoff: float) -> np.ndarray:\n",
    "    \"\"\"Find local peaks in a 2D array of data.\n",
    "\n",
    "    Parameters:\n",
    "    data : numpy.ndarray, shape-(H, W)\n",
    "    cutoff : float\n",
    "         A threshold value that distinguishes background from foreground\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Binary indicator, of the same shape as `data`. The value of\n",
    "    1 indicates a local peak.\"\"\"\n",
    "    \n",
    "    # Generate a rank-2, connectivity-2 binary mask\n",
    "    r2c2 = generate_binary_structure(2, 2)\n",
    "\n",
    "\n",
    "    # Use that neighborhood to find the local peaks in `data`.\n",
    "    # Pass `cutoff` as `amp_min` to `local_peak_locations`.\n",
    "    peak_locations = local_peak_locations(data, r2c2, cutoff)\n",
    "    \n",
    "\n",
    "    # Turns the list of (row, col) peak locations into a shape-(N_peak, 2) array\n",
    "    # Save the result to the variable `peak_locations`\n",
    "    peak_locations = np.array(peak_locations)\n",
    "    return peak_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0f33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_to_fingerprints (local_peaks: np.ndarray, n=15):\n",
    "    \"\"\"Takes in the array local_peaks of freq, time for each peak\n",
    "    for all of the local peaks in a section of a song and takes in\n",
    "    fanout value n.\n",
    "    \n",
    "    It will return fingerprints (in a list) for each peak entered\n",
    "    in an ndarray and the time of the peak (each item in the\n",
    "    fingerprint will be (fanout, time) of each peak)\n",
    "    \"\"\"\n",
    "    \n",
    "    pairs = form_peak_pairs(local_peaks)\n",
    "    peaks = points_to_data(pairs)\n",
    "\n",
    "    fingerprint = [[peaks_to_fanout(\n",
    "        peaks[\n",
    "            np.where(np.multiply(pairs[:,0,0] == i[0], pairs[:,0,1] == i[1]))],\n",
    "        n), i[1]] for i in local_peaks if np.size(\n",
    "        np.where(np.multiply(pairs[:,0,0] == i[0], pairs[:,0,1] == i[1])))>= n]\n",
    "    \n",
    "    ### np.where(np.multiply(pairs[:,0,0] == i[0], pairs[:,0,1] == i[1])) is the index of the peak pair data (row containing it) for each peak i\n",
    "    ### comparing the first and second items of peak 1 with those of peak i\n",
    "    \n",
    "    ## i[1] is the time at peak i, including this in the fingerprint for identification\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Functionality shown in a for loop:\n",
    "    for i in local_peaks: # each peak...\n",
    "        indices = np.array(np.where(np.multiply(pairs[:,0,0] == i[0], pairs[:,0,1] == i[1]))) # index of peak pair data (row containing it) where first peak is peak i (can ignore the second peak since we are only looking forward)\n",
    "        \n",
    "        ### indices[i] --> (row) index of peak-pair P the array peaks (peaks[indices[i], : ] --> original data for peak-pair P)\n",
    "        \n",
    "        selected = peaks[indices]\n",
    "        \n",
    "        if len(selected) >= n: # only going to add it if it's long enough\n",
    "            fanout = peaks_to_fanout(selected, n)\n",
    "    \"\"\"\n",
    "        \n",
    "    ### return list of the fingerprints for each peak\n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23a8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_peak_pairs(local_peaks: np.ndarray):\n",
    "    \"\"\"Takes in the array local_peaks of any number of rows and two columns freq and time\n",
    "    for each of the local peaks and returns an array of each peak-pair from these peaks\n",
    "    \"\"\"\n",
    "    \n",
    "    pairs = np.array([(peak1,peak2) for peak2 in local_peaks for peak1 in local_peaks if peak1[1] < peak2[1]])    \n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8d0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_data(points: np.ndarray):\n",
    "    \"\"\"Takes in an array of freq and time data for each peak in each peak-pair\n",
    "    (where the first listed is one that occurs first) and returns a 2d array\n",
    "    which contains three columns and number of rows equivalent to the number of \n",
    "    peak-pairs entered\n",
    "        Col 1 --> frequency at point 1 (point 1 must occur first)\n",
    "        Col 2 --> frequency at point 2\n",
    "        Col 3 --> time elapsed between points\n",
    "    \"\"\"\n",
    "    data = np.array([[pair[0,0], pair[1,0], pair[1,1]-pair[0,1]] for pair in points])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efcea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_to_fanout(selected_peaks: np.ndarray, n):\n",
    "    \"\"\"Takes in a 2d array selected_peaks of selected peak-pair\n",
    "    data in the same formatting as the full array, and containing\n",
    "    all of the peak-pairs with a particular peak as peak 1. Also\n",
    "    takes in the fanout value n.\n",
    "    \n",
    "    Returns the fanout for this peak\n",
    "\n",
    "                                  [[fi, fi+1, delta_t(i,i+1)]\n",
    "                                   [fi, fi+2, delta_t(i,i+2)],\n",
    "        fanout (for peak i)  =               ...,\n",
    "                                   [fi, fi+n, delta_t(i,i+n)]]    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    delta_fs = selected_peaks[:,1]-selected_peaks[:,0] # array of change in frequencies for our peak pairs\n",
    "    delta_ts = selected_peaks[:,2] # array of change in times for our peak pairs\n",
    "\n",
    "    ### for each index i,\n",
    "    ###     selected_peaks[i] --> peak-pair P data (this is just a segment of the original data; just the peak-pairs contianing our particular peak)\n",
    "    ###     delta_fs[i]       --> change in frequency for peak-pair P\n",
    "    ###     delta_ts[i]       --> change in time for peak-pair P\n",
    "\n",
    "\n",
    "    # an array of indices pointing towards our selected peak-pair data\n",
    "    # (selected_peaks_sorted[i] --> index of i'th closest peak (index pointing towards our selected peak-pair data arrays))\n",
    "    selected_peaks_sorted = sort_peaks(delta_fs, delta_ts) \n",
    "\n",
    "    #selected_peaks_sorted[0:n] are the indices of the peaks within the fanout\n",
    "    fanout_inds = selected_peaks_sorted[0:n]\n",
    "    fanout_peaks = selected_peaks[fanout_inds]\n",
    "\n",
    "    ###    fanout for this peak = an array of [[fi, fi+1, delta_t(i,i+1)]\n",
    "    ###                                        [fi, fi+2, delta_t(i,i+2)],\n",
    "    ###                                                   ...,\n",
    "    ###                                        [fi, fi+n, delta_t(i,i+n)]]\n",
    "    \n",
    "    fanout = fanout_peaks[:,0:3]\n",
    "    return fanout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98124354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_peaks (delta_fs: np.ndarray, delta_ts: np.ndarray):\n",
    "    \"\"\"Takes in two 1 dimensional nd arrays delta_fs and delta_ts\n",
    "    of the same length which both point towards data from the same\n",
    "    selected peak-pairs and for which the value of each at each same\n",
    "    index point to the same individual peak-pair\n",
    "        - this means that for each index i, delta_fs[i] and delta_ts[i]\n",
    "          correspond to the same peak-pair\n",
    "        - the delta_f and delta_t values should be from all of the\n",
    "          peak-pairs for which a particular peak is the first peak in\n",
    "          the pair\n",
    "    \n",
    "    It returns an nd array where the values of which represent the\n",
    "    indices of delta_ts, delta_fs, and other arrays which point to the\n",
    "    same data in the same order sorted by time then frequency (eg. the\n",
    "    first value of the output array is the index of the smallest\n",
    "    delta_t, second is the next smallest, etc. (where identical delta_ts\n",
    "    will be ordered by smallest delta_f to greatest))\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ### get indices sorted based on delta_t values of our selected data (sorted_t)\n",
    "    sorted_t = np.argsort(delta_ts)\n",
    "\n",
    "    # we need to make sure that any duplicate times are sorted by frequency:\n",
    "\n",
    "    #finding the time values\n",
    "    time_counts = Counter(delta_ts)\n",
    "    arr_counts = np.array(list(time_counts.items())) # an array of the items in the Counter time_counts\n",
    "    duplicates_ind = np.where(arr_counts[:,1] >1) # finding the indexes of where there are more than one of each time\n",
    "    if len(duplicates_ind) > 0: # only continue to sort if there are duplicates\n",
    "        duplicates_times = arr_counts[:, 0][duplicates_ind] #finding the time values based on the indices in the counter\n",
    "\n",
    "        # list of an array of indices of each duplicate time\n",
    "        # (indices are the indices pointing towards data in delta_fs, delta_ts, and t_sorted, NOT the values in t_sorted which will be used as indices (to get those do t_sorted[unsorted_by_freq]))\n",
    "        unsorted_by_freq = [list(np.where(delta_ts == time)[0]) for time in duplicates_times]\n",
    "\n",
    "        # list of an array containing the new index values pointed to by each array of indices in unsorted_by_freq, sorted by frequency\n",
    "        # (these values are the index values to put into the array of indices)\n",
    "        # each item = reorder of the values of sorted_t by sorting by frequency for each index_arr in the unsorted_by_freq lsit\n",
    "        sorted_by_freq = [list(sorted_t[index_arr][np.argsort(delta_fs[sorted_t[index_arr]])]) for index_arr in unsorted_by_freq]                \n",
    "        # put back in:\n",
    "        ## 'flattening' the lists so as to be able to index with them\n",
    "        flat_unsorted = []\n",
    "        flat_sorted = []\n",
    "        [[flat_unsorted.append(inner_vals) for inner_vals in value] for value in unsorted_by_freq]\n",
    "        [[flat_sorted.append(inner_vals) for inner_vals in value] for value in sorted_by_freq]\n",
    "        ## putting these into sorted\n",
    "        sorted_fully = sorted_t.copy()\n",
    "        sorted_fully[flat_unsorted] = flat_sorted\n",
    "        \n",
    "        return sorted_fully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9031a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Databases\n",
    "with open(\"DB_Names.pkl\", mode=\"rb\") as opened_file:\n",
    "    database_names = pickle.load(opened_file)\n",
    "with open(\"DB_Fingerprints.pkl\", mode=\"rb\") as opened_file:\n",
    "    database_fingerprints = pickle.load(opened_file)\n",
    "#add functions\n",
    "def add_to_DBN(song_name: str, artist: str):\n",
    "    database_names[len(database_names)+1] = (song_name,artist)\n",
    "    \n",
    "    \n",
    "def add_to_DBF(fingerprint_arr: tuple, time_occured: float,  song_ID: int):\n",
    "    if (fingerprint_arr in database_fingerprints.keys()):\n",
    "        temp_tuple = database_fingerprints[fingerprint_arr] + (song_ID,time_occured)\n",
    "        database_fingerprints[fingerprint_arr] = temp_tuple\n",
    "    else:\n",
    "        database_fingerprints[fingerprint_arr] = (song_ID, time_occured)\n",
    "        \n",
    "def del_id(ex_dict, id_n):\n",
    "    del ex_dict[id_n]\n",
    "\n",
    "def get_all(ex_dict: dict):\n",
    "    # ex_dict is the dictionary which stores a tuple of songs and artists as the value of keys which are ids.\n",
    "    return [ex_dict[i] for i in range(1,len(ex_dict)+1)]\n",
    "    # i refers to the id number, range begins at 1 and len is added by 1 because id begins (here at least) with 1, not 0. \n",
    "\n",
    "def get_song_names(ex_dict: dict):\n",
    "    return [ex_dict[i][0] for i in range(1, len(ex_dict)+1)]\n",
    "\n",
    "def get_artists(ex_dict: dict):\n",
    "    return [ex_dict[i][1] for i in range(1, len(ex_dict)+1)]\n",
    "\n",
    "#add_to_DBF(tuple(np.array([0,0,0,1])) ,0, 1)\n",
    "#add_to_DBF(tuple(np.array([0,0,0,0])) ,1, 1)\n",
    "#add_to_DBF(tuple(np.array([0,0,0,0])) ,2, 1)\n",
    "#del_id(database_fingerprints, tuple(np.array([0,0,0,0])))\n",
    "#database_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7008500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clips\n",
    "def short_clip(percent, data): # percent refers to the percentage of the original file the new file should be\n",
    "    # example: a 15 second clip with a percent of 10% would return files that are 1.5 seconds long.\n",
    "    # Where in the original clip the function pulls from is randomly chosen.\n",
    "    percent /= 100\n",
    "    start = randint(0, len(data)-int(len(data)*percent)) # Chooses a random starting point for the new file, avoids out of bounds errors\n",
    "    print(\"start ind is\", start, \"of\", len(data)-int(len(data)*percent), \"possible inds\")\n",
    "    return data[start:start+int(len(data)*percent)]\n",
    "\n",
    "def multiple_clips(percent, data, num_clips):\n",
    "    clips = [] # nd array would also work\n",
    "    for i in range(num_clips):\n",
    "        clips.append(short_clip(15, data))\n",
    "    return clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d0134c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_names = {}\n",
    "for file_name in os.listdir('./MusicMP3s')[1:]:\n",
    "    add_to_DBN(file_name.split(' - ')[1].split('.')[0],file_name.split(' - ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "797f7b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('The Music of the Night', 'Andrew Lloyd Webber'),\n",
       " 2: ('O Canto Da Cidade', 'Daniela Mercury'),\n",
       " 3: ('Space Oddity', 'David Bowie'),\n",
       " 4: ('I Bet My Life', 'Imagine Dragons'),\n",
       " 5: ('Little Wing', 'Jimi Hendrix'),\n",
       " 6: ('Someone You Loved', 'Lewis Capaldi'),\n",
       " 7: ('I Dont Really Care', 'Mat Kearney'),\n",
       " 8: ('Never Gonna Give You Up', 'Rick Astley')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9c6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks2fp(peaks: np.array, fan_value=15):\n",
    "    for n, (t1,f1) in enumerate(peaks):\n",
    "        for t2, f2 in peaks[n+1:n+fan_value+1]:\n",
    "            yield (f1,f2,t2-t1), t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d2f1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_file_to_fingerprints(S: np.ndarray, n=15):\n",
    "    \"\"\"Takes in the spectogram of a song S and the fanout value n and returns the list of fingerprints\"\"\"\n",
    "    \n",
    "    # NATHANS CODE\n",
    "    log_S = np.log(S).ravel()  # ravel flattens 2D spectrogram into a 1D array\n",
    "    ind = round(len(log_S) * 0.9)  # find the index associated with the 90th percentile log-amplitude\n",
    "    cutoff_log_amp = np.partition(log_S, ind)[ind]  # find the actual 90th percentile log-amplitude\n",
    "    print(\"Data Unraveled!\")\n",
    "    # END NATHANS CODE\n",
    "    \n",
    "    local_peak_locations = local_peaks_mask(S, cutoff_log_amp)\n",
    "    print(\"Peaks Found!\")\n",
    "    \n",
    "    fingerprints = peaks2fp(local_peak_locations, n)\n",
    "    print(\"Fingerprints Created!\")\n",
    "    \n",
    "    return fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b73c5cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DB_Names.pkl\", mode=\"wb\") as opened_file:\n",
    "    pickle.dump(database_names,opened_file)\n",
    "with open(\"DB_Fingerprints.pkl\", mode=\"wb\") as opened_file:\n",
    "    pickle.dump(database_fingerprints,opened_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0b194f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MusicMP3s/Andrew Lloyd Webber - The Music of the Night.mp3 loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svaud\\AppData\\Local\\Temp/ipykernel_11540/2173198592.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  log_S = np.log(S).ravel()  # ravel flattens 2D spectrogram into a 1D array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Unraveled!\n",
      "Peaks Found!\n",
      "Fingerprints Created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object peaks2fp at 0x000001B480735AC0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file_to_fingerprints(from_mp3(\"./MusicMP3s/Andrew Lloyd Webber - The Music of the Night.mp3\",44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e61912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
